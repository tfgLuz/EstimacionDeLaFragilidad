# app.py 
import streamlit as st
import pandas as pd
import os
import subprocess
import joblib

# --- 1. Configuraci√≥n de la P√°gina y Constantes ---
st.set_page_config(
    page_title="Estimador de Fragilidad",
    page_icon="üë®‚Äç‚öïÔ∏è",
    layout="wide"
)

st.title("üë®‚Äç‚öïÔ∏è Estimador de Fragilidad Basado en Datos de Smartwatch")

# --- Constantes de Archivos ---
UPLOAD_DIR = "temp_uploads"
ACTIVITY_FILE = os.path.join(UPLOAD_DIR, "activity.csv")
RECHARGE_FILE = os.path.join(UPLOAD_DIR, "recharge.csv")
SLEEP_FILE = os.path.join(UPLOAD_DIR, "sleep.csv")
TEMP_FILE = os.path.join(UPLOAD_DIR, "temperature.csv")
CONSOLIDATED_FILE = os.path.join(UPLOAD_DIR, "datos_consolidados.csv")
COMPLETE_RAW_FILE = os.path.join(UPLOAD_DIR, "dataset_completo_raw.csv")
COMPLETE_CLEANED_FILE = os.path.join(UPLOAD_DIR, "dataset_completo_limpio.csv")
PIPELINE_FILE = 'fragility_pipeline.joblib'

os.makedirs(UPLOAD_DIR, exist_ok=True)

# --- 2. Funciones Auxiliares ---
APP_DIR = os.path.dirname(os.path.abspath(__file__))

def run_script(script_name, args=[]):
    """Ejecuta un script externo y muestra su salida."""
    script_path = os.path.join(APP_DIR, script_name)
    
    command = ["python", script_path] + args
    try:
        result = subprocess.run(
            command, capture_output=True, text=True, check=True, encoding='latin-1'
        )
        st.info(f"Salida de '{script_name}':\n{result.stdout}")
        return True
    except FileNotFoundError:
        st.error(f"Error: No se encontr√≥ el int√©rprete de Python o el script '{script_path}'.")
        return False
    except subprocess.CalledProcessError as e:
        st.error(f"Error al ejecutar '{script_name}':\n{e.stderr}")
        return False

def display_prediction_results(df_to_predict, probabilities):
    """Toma las probabilidades y muestra los resultados en un formato amigable."""
    predictions_numeric = probabilities.argmax(axis=1)
    
    label_map = {
        0: 'Fr√°gil',
        1: 'Pre-fr√°gil',
        2: 'Robusto'
    }
    predictions_text = [label_map.get(p, 'Desconocido') for p in predictions_numeric]

    results_df = pd.DataFrame({'date': df_to_predict['date']})
    results_df['predicted_frailty'] = predictions_text
    
    for class_index, class_name in label_map.items():
        if class_index < probabilities.shape[1]:
            results_df[f'prob_{class_name}'] = probabilities[:, class_index].round(3)

    st.success("¬°Predicci√≥n completada!")
    st.dataframe(results_df)
    st.subheader("Resumen de la Clasificaci√≥n")
    st.bar_chart(results_df['predicted_frailty'].value_counts())


    # --- Gr√°fico de l√≠nea para la evoluci√≥n ---
    st.subheader("Evoluci√≥n de la Fragilidad en el Tiempo")
    
    # Definir el orden de las categor√≠as para que el eje Y se muestre l√≥gicamente
    category_order = ['Robusto', 'Pre-fr√°gil', 'Fr√°gil']
    
    # Crear una copia del dataframe para la gr√°fica
    plot_df = results_df.copy()
    
    # Convertir la columna de predicci√≥n a un tipo categ√≥rico con orden
    plot_df['predicted_frailty'] = pd.Categorical(
        plot_df['predicted_frailty'], 
        categories=category_order, 
        ordered=True
    )
    
    # Ordenar por fecha para que la l√≠nea tenga sentido
    plot_df = plot_df.sort_values('date')

    # Para st.line_chart, es mejor tener la fecha como √≠ndice
    plot_df = plot_df.set_index('date')

    # Generar el gr√°fico de l√≠nea
    st.line_chart(
        plot_df['predicted_frailty']
    )

def predict_on_dataframe(df):
    """Funci√≥n central que realiza la predicci√≥n sobre un dataframe ya limpio."""
    try:
        pipeline = joblib.load(os.path.join(APP_DIR, PIPELINE_FILE))
        
        numeric_features = [
            'age', 'active-steps', 'active-calories', 'calories', 'duration_minutes',
            'heart_rate_avg', 'heart_rate_variability_avg', 'ans_charge', 'sleep_score',
            'light_sleep_min', 'deep_sleep_min', 'rem_sleep_min', 'interruptions_min',
            'breathing_rate_avg', 'temp_amplitude'
        ]
        
        missing_cols = list(set(numeric_features) - set(df.columns))
        if missing_cols:
            st.error(f"Error Cr√≠tico: Faltan columnas para la predicci√≥n: {missing_cols}")
            return

        probabilities = pipeline.predict_proba(df)
        display_prediction_results(df, probabilities)

    except FileNotFoundError:
        st.error(f"Error: No se encontr√≥ el archivo del modelo '{PIPELINE_FILE}'. Aseg√∫rate de haber entrenado el modelo.")
    except Exception as e:
        st.error(f"Ocurri√≥ un error durante la predicci√≥n: {e}")

# --- 3. Interfaz con Pesta√±as ---
tab1, tab2, tab3 = st.tabs([
    "üìò Instrucciones",
    "üöÄ Predecir desde 4 Archivos", 
    "üìÇ Examinar Dataset Completo",
])

# --- Pesta√±a 1: Instrucciones ---
with tab1:
    st.header("üìò Instrucciones de Uso y Formato")

    st.subheader("Opci√≥n A: Predecir desde 4 Archivos")
    st.markdown("""
    1.  **Introduce la Edad**: Escribe la edad del sujeto en el campo num√©rico.
    2.  **Carga los 4 Archivos**: Sube cada uno de los ficheros CSV correspondientes.
    3.  **Ejecuta**: Pulsa el bot√≥n "Unir, Limpiar y Predecir".
    
    La aplicaci√≥n unir√° los archivos por fecha, eliminar√° los d√≠as que no tengan datos completos en los 4 ficheros, a√±adir√° la edad y realizar√° la predicci√≥n.
    """)

    st.subheader("Opci√≥n B: Examinar Dataset Completo")
    st.markdown("""
    1.  **Prepara tu Archivo**: Aseg√∫rate de que tu fichero CSV contiene **todas** las columnas necesarias que usa el modelo, incluyendo `date` y `age`.
    2.  **Carga el Archivo**: Sube el fichero CSV completo.
    3.  **Ejecuta**: Pulsa el bot√≥n "Limpiar y Predecir Dataset".

    La aplicaci√≥n tomar√° tu archivo, rellenar√° cualquier valor `NaN` que encuentre usando la mediana (para n√∫meros) o la moda (para texto), y luego realizar√° la predicci√≥n.
    """)

    st.subheader("Columnas Requeridas por el Modelo")
    st.code("""
        # El modelo necesita obligatoriamente estas columnas:
        date, age, active-steps, active-calories, calories, duration_minutes,
        heart_rate_avg, heart_rate_variability_avg, ans_charge, sleep_score,
        light_sleep_min, deep_sleep_min, rem_sleep_min, interruptions_min,
        breathing_rate_avg, temp_amplitude
            """, language="text")
# --- Pesta√±a 2: Flujo de 4 archivos + edad ---
with tab2:
    st.header("Opci√≥n A: Predecir uniendo 4 archivos")
    st.write("Carga los 4 ficheros CSV por separado. La edad se introduce manualmente.")
    
    age_input = st.number_input(
        "Introduce la Edad del Usuario", 
        min_value=18, max_value=120, value=75, step=1, key="age_input_tab1"
    )
    
    col1, col2 = st.columns(2)
    with col1:
        uploaded_activity = st.file_uploader("1. Fichero de Actividad", type="csv", key="act_up")
        uploaded_recharge = st.file_uploader("2. Fichero de Recuperaci√≥n", type="csv", key="rec_up")
    with col2:
        uploaded_sleep = st.file_uploader("3. Fichero de Sue√±o", type="csv", key="sle_up")
        uploaded_temp = st.file_uploader("4. Fichero de Temperatura", type="csv", key="tem_up")
    
    if st.button("Unir, Limpiar y Predecir", key="btn_tab1"):
        if all([uploaded_activity, uploaded_recharge, uploaded_sleep, uploaded_temp]):
            # Guardar archivos
            with open(ACTIVITY_FILE, "wb") as f: f.write(uploaded_activity.getbuffer())
            with open(RECHARGE_FILE, "wb") as f: f.write(uploaded_recharge.getbuffer())
            with open(SLEEP_FILE, "wb") as f: f.write(uploaded_sleep.getbuffer())
            with open(TEMP_FILE, "wb") as f: f.write(uploaded_temp.getbuffer())
            st.success("Archivos cargados.")

            # Unir y limpiar con prepararDF.py
            st.subheader("Paso 1: Uniendo y Limpiando Datasets")
            input_files = [ACTIVITY_FILE, RECHARGE_FILE, SLEEP_FILE, TEMP_FILE]
            if run_script("prepararDF.py", ["--inputs"] + input_files + ["--output", CONSOLIDATED_FILE]):
                # A√±adir edad
                df = pd.read_csv(CONSOLIDATED_FILE)
                df['age'] = age_input
                
                # Predecir
                st.subheader("Paso 2: Realizando la Predicci√≥n")
                predict_on_dataframe(df)
        else:
            st.error("Por favor, carga los cuatro archivos necesarios.")

# --- Pesta√±a 3: Flujo de 1 archivo completo ---
with tab3:
    st.header("Opci√≥n B: Predecir desde un Dataset Completo")
    st.write("Carga un √∫nico fichero CSV que ya contenga **todas las columnas, incluida la edad**.")
    
    uploaded_complete = st.file_uploader("Cargar Fichero de Datos Consolidado", type="csv", key="comp_up")

    if st.button("Limpiar y Predecir Dataset", key="btn_tab2"):
        if uploaded_complete:
            # Guardar archivo
            with open(COMPLETE_RAW_FILE, "wb") as f:
                f.write(uploaded_complete.getbuffer())
            st.success("Archivo consolidado cargado.")

            # Limpiar NaNs con limpiar_dataset.py
            st.subheader("Paso 1: Limpiando el Dataset (imputando NaNs)")
            if run_script("limpiar_dataset.py", [COMPLETE_RAW_FILE, COMPLETE_CLEANED_FILE]):
                # Cargar dataframe limpio y predecir
                df_cleaned = pd.read_csv(COMPLETE_CLEANED_FILE)
                st.subheader("Paso 2: Realizando la Predicci√≥n")
                predict_on_dataframe(df_cleaned)
        else:
            st.error("Por favor, carga un archivo consolidado.")



